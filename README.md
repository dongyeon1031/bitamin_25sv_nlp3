# ì‹¤í–‰ ê°€ì´ë“œ

## ğŸ–¥ï¸ ì‚¬ì „ ìš”êµ¬ì‚¬í•­
- Python 3.10 ì´ìƒ
- pip ìµœì‹  ë²„ì „
- ê°€ìƒí™˜ê²½ ê¶Œì¥ (venv ë˜ëŠ” conda)
- NVIDIA GPU + CUDA ì„¤ì¹˜ë¨

---

## 1. ì‹¤í–‰í™˜ê²½ êµ¬ì„±

### ë¦¬ëˆ…ìŠ¤ í™˜ê²½ (CUDA + llama-cpp-python)

```bash
chmod +x install.sh
./install.sh
```

### ìœˆë„ìš° í™˜ê²½ (CUDA ì„¤ì • í¬í•¨)

```bash
pip install -r requirements.txt
CMAKE_ARGS="-DLLAMA_CUBLAS=OFF -DGGML_CUDA=ON" pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade
```
---